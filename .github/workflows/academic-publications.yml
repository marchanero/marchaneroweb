name: Academic Publications Check

on:
  push:
    branches: [main]
    paths:
      - 'src/data/publications.js'
      - 'src/data/research.js'
      - 'src/pages/proyectos.astro'
  # Ejecución programada mensual
  schedule:
    - cron: '0 9 1 * *'  # El primer día de cada mes a las 9:00 AM UTC
  # Permite ejecutar manualmente
  workflow_dispatch:
    inputs:
      scholar_check:
        description: 'Verificar también citas en Google Scholar'
        type: boolean
        default: false
      orcid_check:
        description: 'Verificar también ORCID'
        type: boolean
        default: false

jobs:
  validate-publications:
    name: Validate Academic Publications
    runs-on: ubuntu-latest

    steps:
      - name: Checkout código
        uses: actions/checkout@v4

      - name: Configurar Node.js
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Instalar dependencias
        run: npm ci

      - name: Build del sitio
        run: npm run build

      - name: Verificar enlaces a publicaciones
        run: |
          mkdir -p link-check-results
          
          # Extraer todos los enlaces de la página de proyectos
          grep -o 'https://[^"]*' dist/proyectos/index.html > link-check-results/all-links.txt
          
          # Filtrar solo enlaces académicos
          grep -E 'doi.org|researchgate|scholar.google|orcid|academia.edu|sciencedirect' link-check-results/all-links.txt > link-check-results/academic-links.txt
          
          echo "Enlaces académicos encontrados:"
          cat link-check-results/academic-links.txt
          
          # Instalar herramienta para verificar enlaces
          npm install --no-save broken-link-checker
          
          # Verificar enlaces académicos (solo reportando, no fallando el workflow)
          echo "Verificando enlaces académicos..."
          cat link-check-results/academic-links.txt | xargs -I {} npx blc {} --follow --recursive --filter-level 2 || echo "Algunos enlaces pueden requerir revisión"

      - name: Guardar resultados de verificación
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: academic-links-check
          path: link-check-results/

  doi-validation:
    name: DOI References Validation
    runs-on: ubuntu-latest
    needs: validate-publications

    steps:
      - name: Checkout código
        uses: actions/checkout@v4

      - name: Configurar entorno Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Instalar dependencias Python
        run: |
          python -m pip install --upgrade pip
          pip install requests beautifulsoup4

      - name: Extraer y validar DOIs
        run: |
          cat > validate_doi.py << 'EOF'
          import re
          import os
          import sys
          import json
          import requests
          from bs4 import BeautifulSoup

          # Buscar archivos JavaScript o JSON que puedan contener datos de publicaciones
          data_files = []
          for root, _, files in os.walk('src'):
              for file in files:
                  if file.endswith('.js') or file.endswith('.json'):
                      data_files.append(os.path.join(root, file))

          print(f"Encontrados {len(data_files)} posibles archivos de datos")

          # Expresión regular para encontrar DOIs
          doi_pattern = r'10\.\d{4,}\/[^\s"\']*'
          dois = []

          # Extraer DOIs de archivos
          for file_path in data_files:
              try:
                  with open(file_path, 'r', encoding='utf-8') as file:
                      content = file.read()
                      found_dois = re.findall(doi_pattern, content)
                      if found_dois:
                          print(f"Encontrados {len(found_dois)} DOIs en {file_path}")
                          dois.extend(found_dois)
              except Exception as e:
                  print(f"Error procesando {file_path}: {e}")

          # Eliminar duplicados
          dois = list(set(dois))
          print(f"Total de DOIs únicos encontrados: {len(dois)}")

          # Validar DOIs
          results = {'valid': [], 'invalid': [], 'error': []}

          for doi in dois:
              try:
                  # Limpiar el DOI de posibles caracteres extra
                  doi = doi.strip(',;."\'')
                  url = f"https://doi.org/{doi}"
                  
                  # Intentar resolver el DOI
                  response = requests.get(url, 
                                         headers={'Accept': 'application/json'},
                                         allow_redirects=True, 
                                         timeout=10)
                  
                  if response.status_code == 200:
                      results['valid'].append({'doi': doi, 'url': url})
                      print(f"✅ DOI válido: {doi}")
                  else:
                      results['invalid'].append({'doi': doi, 'status': response.status_code})
                      print(f"❌ DOI inválido: {doi} (Status: {response.status_code})")
              except Exception as e:
                  results['error'].append({'doi': doi, 'error': str(e)})
                  print(f"⚠️ Error al validar DOI: {doi} - {e}")

          # Guardar resultados
          with open('doi-validation-results.json', 'w') as f:
              json.dump(results, f, indent=2)

          print("\nResumen de validación de DOIs:")
          print(f"Total DOIs: {len(dois)}")
          print(f"Válidos: {len(results['valid'])}")
          print(f"Inválidos: {len(results['invalid'])}")
          print(f"Errores: {len(results['error'])}")

          # Salir con código de error si hay DOIs inválidos
          if len(results['invalid']) > 0:
              print("\n⚠️ Se encontraron DOIs inválidos que requieren revisión.")
          EOF

          python validate_doi.py

      - name: Guardar resultados de validación DOI
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: doi-validation-results
          path: doi-validation-results.json

      - name: Notificar problemas de DOI
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            
            try {
              if (fs.existsSync('doi-validation-results.json')) {
                const results = JSON.parse(fs.readFileSync('doi-validation-results.json', 'utf8'));
                
                if (results.invalid.length > 0 || results.error.length > 0) {
                  github.rest.issues.create({
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    title: 'Revisión necesaria: Referencias DOI inválidas',
                    body: `## Revisión de referencias académicas necesaria
                    
                    Se han encontrado problemas con las siguientes referencias DOI:
                    
                    ### DOIs Inválidos (${results.invalid.length}):
                    ${results.invalid.map(item => `- \`${item.doi}\` (Status: ${item.status})`).join('\n')}
                    
                    ### Errores de validación (${results.error.length}):
                    ${results.error.map(item => `- \`${item.doi}\`: ${item.error}`).join('\n')}
                    
                    Por favor, revise y corrija estas referencias académicas para mantener la integridad del sitio web.
                    
                    [Ver resultados completos en el workflow](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})
                    `,
                    labels: ['bug', 'referencias-academicas']
                  });
                }
              }
            } catch (error) {
              core.setFailed(`Error al procesar resultados DOI: ${error.message}`);
            }
